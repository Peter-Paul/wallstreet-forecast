{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas_datareader as pdr\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import seaborn as sns\n",
    "import sklearn as skl\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "import sklearn as skl\n",
    "from alpha_vantage.timeseries import TimeSeries\n",
    "from alpha_vantage.techindicators import TechIndicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "crypto = ['DASH-USD','EOS-USD','LTC-USD','BNB-USD','TRX-USD','XLM-USD','BCH-USD', 'DASH-USD']\n",
    "commodities = ['ES=F', 'CL=F', 'GC=F', 'NG=F', 'ZN=F', 'NQ=F', 'C=F', 'S=F']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = \"QO234RMNT7YYSXZ3\"\n",
    "period = 60\n",
    "ts = TimeSeries(key=api_key, output_format=\"pandas\")\n",
    "allrawdfs = []\n",
    "def extract_df(data):\n",
    "    for i in data:\n",
    "        allrawdfs.append(ts.get_intraday(i.upper(), interval=\"5min\", outputsize=\"full\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_df(crypto[ : 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_df(crypto[ 4 : ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_df(commodities[ : 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_df(commodities[ 4 : ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "alldfs = []\n",
    "def extract_vols(data):\n",
    "    mean_volumes = []\n",
    "    for i in data:\n",
    "        mean_volumes.append(i['5. volume'].mean())\n",
    "    vol_array = np.array(mean_volumes)\n",
    "    for i in data:\n",
    "        if i['5. volume'].mean() > np.quantile(vol_array, 0.5):\n",
    "            alldfs.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_vols(allrawdfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_with_diffs = []\n",
    "def add_diffs(data):\n",
    "    for i in data:\n",
    "        i['diff'] = i['4. close'] - i['1. open']\n",
    "        dfs_with_diffs.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_diffs(alldfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "allPrice = []\n",
    "def getclose(data):\n",
    "    for i in data:\n",
    "        new  = list(i['4. close'].to_numpy())\n",
    "        new.reverse()\n",
    "        allPrice.append(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "getclose(dfs_with_diffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = []\n",
    "def get_support_resistance(data):\n",
    "    result = []\n",
    "    all_data = []\n",
    "    counts = []\n",
    "    for x in data:\n",
    "        all_data.append( [ x, data.count(x)] )\n",
    "        counts.append(data.count(x))\n",
    "    unrepeated = []\n",
    "    for x in all_data:\n",
    "        if x not in unrepeated:\n",
    "            unrepeated.append(x)\n",
    "    sorted_result = sorted(unrepeated, key = lambda i: i[1], reverse=True)\n",
    "    arr = np.array(sorted_result)\n",
    "\n",
    "    for x in list(arr):\n",
    "        if x[1] > np.quantile(np.array(counts), 0.78):\n",
    "            result.append(list(x))\n",
    "    return result\n",
    "def get_s_r(data):\n",
    "    for i in data:\n",
    "        final.append(get_support_resistance(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_s_r(allPrice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "converted_dfs = []\n",
    "def covert_to_list(data):\n",
    "    for i in data:\n",
    "        new = i.values.tolist()\n",
    "        converted_dfs.append(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "covert_to_list(dfs_with_diffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "extracted_points = []\n",
    "extracted_inputs = []\n",
    "extracted_outputs = []\n",
    "def get_spread(data, price):\n",
    "    inputs = []\n",
    "    outputs = []\n",
    "    res = []\n",
    "    for x in data:  \n",
    "        for i in price:\n",
    "        # by doing this, we are able to extract these points from the entire list and get those with a good spread\n",
    "            if x[3] == i[0]:\n",
    "                diff = x[0] - x[3]\n",
    "                inputs.append(list(data[ data.index(x) - 5 : data.index(x)]))\n",
    "                outputs.append(list(data[ data.index(x) : data.index(x) + 8 ]))\n",
    "                res.append(x)\n",
    "    return [res, inputs, outputs]\n",
    "def get_s(data, price):\n",
    "    for a,b in zip(data, price):\n",
    "        extracted_points.append(get_spread(a,b)[0])\n",
    "        extracted_inputs.append(get_spread(a,b)[1])\n",
    "        extracted_outputs.append(get_spread(a,b)[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_s(converted_dfs,final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "diff_on_prev = []\n",
    "def get_ins(data):\n",
    "    newDiff =[]\n",
    "    for x in data:\n",
    "        def extract(v):\n",
    "            return v[5]\n",
    "        result = map(extract, x)\n",
    "        newDiff.append(list(result))\n",
    "    return newDiff\n",
    "def get_i(data):\n",
    "    for i in data:\n",
    "        diff_on_prev.append(get_ins(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_i(extracted_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sum_diff_on_next = []\n",
    "def get_outs(data):\n",
    "    rightD = []\n",
    "    summation = []\n",
    "    for r in data:\n",
    "        def extractr(f):\n",
    "            return f[5]\n",
    "        resultr = map(extractr, r)\n",
    "        rightD.append(list(resultr))\n",
    "    for p in rightD:\n",
    "        summation.append(sum(p))\n",
    "    return summation\n",
    "def get_o(data):\n",
    "    for i in data:\n",
    "        sum_diff_on_next.append(get_outs(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_o(extracted_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    " transact_or_not = []\n",
    " def get_decision(data):\n",
    "    sum_np_array = np.array(data)\n",
    "    decision = []\n",
    "    for t in data:\n",
    "        if abs(t) > np.quantile(sum_np_array, 0.99):\n",
    "        # the 1 stands for a transaction while the 0 stands for no transaction\n",
    "            decision.append(1)\n",
    "        else:\n",
    "            decision.append(0)\n",
    "    return decision\n",
    "def get_d(data):\n",
    "    for i in data:\n",
    "        transact_or_not.append(get_decision(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_d(sum_diff_on_next)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We figured out that these only provide us with less transactions and has small breakouts. We have to get much more data that's volatile and extract better equilibriums with better breakouts. Run different apis after every minute, increase the outputs, figure out a relation with SMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "2.3703000000000145"
     },
     "metadata": {},
     "execution_count": 71
    }
   ],
   "source": [
    "np.array(sum_diff_on_next[7]).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "t_or_n = []\n",
    "combinedinputs = []\n",
    "combinedoutputs = []\n",
    "for a,b,c in zip(diff_on_prev,sum_diff_on_next,transact_or_not):\n",
    "    combinedinputs.extend(a)\n",
    "    combinedoutputs.extend(b)\n",
    "    t_or_n.extend(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                I1           I2           I3           I4           I5  \\\ncount  5356.000000  5356.000000  5356.000000  5356.000000  5356.000000   \nmean      0.018059     0.009134     0.008989     0.003217    -0.015195   \nstd       0.954822     0.952051     0.977665     1.004808     0.985326   \nmin     -13.750000   -17.000000   -17.000000   -13.750000   -13.750000   \n25%      -0.001500    -0.001600    -0.001300    -0.001400    -0.001700   \n50%       0.000000     0.000000     0.000000     0.000000     0.000100   \n75%       0.001000     0.000700     0.001200     0.001025     0.000700   \nmax      12.250000    14.250000    14.250000    14.250000    14.250000   \n\n       Transaction      Outputs  \ncount  5358.000000  5358.000000  \nmean      0.155842     0.068179  \nstd       0.362739     2.599773  \nmin       0.000000   -20.750000  \n25%       0.000000    -0.006100  \n50%       0.000000    -0.000100  \n75%       0.000000     0.001775  \nmax       1.000000    49.250000  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>I1</th>\n      <th>I2</th>\n      <th>I3</th>\n      <th>I4</th>\n      <th>I5</th>\n      <th>Transaction</th>\n      <th>Outputs</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>5356.000000</td>\n      <td>5356.000000</td>\n      <td>5356.000000</td>\n      <td>5356.000000</td>\n      <td>5356.000000</td>\n      <td>5358.000000</td>\n      <td>5358.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.018059</td>\n      <td>0.009134</td>\n      <td>0.008989</td>\n      <td>0.003217</td>\n      <td>-0.015195</td>\n      <td>0.155842</td>\n      <td>0.068179</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.954822</td>\n      <td>0.952051</td>\n      <td>0.977665</td>\n      <td>1.004808</td>\n      <td>0.985326</td>\n      <td>0.362739</td>\n      <td>2.599773</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>-13.750000</td>\n      <td>-17.000000</td>\n      <td>-17.000000</td>\n      <td>-13.750000</td>\n      <td>-13.750000</td>\n      <td>0.000000</td>\n      <td>-20.750000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>-0.001500</td>\n      <td>-0.001600</td>\n      <td>-0.001300</td>\n      <td>-0.001400</td>\n      <td>-0.001700</td>\n      <td>0.000000</td>\n      <td>-0.006100</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000100</td>\n      <td>0.000000</td>\n      <td>-0.000100</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>0.001000</td>\n      <td>0.000700</td>\n      <td>0.001200</td>\n      <td>0.001025</td>\n      <td>0.000700</td>\n      <td>0.000000</td>\n      <td>0.001775</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>12.250000</td>\n      <td>14.250000</td>\n      <td>14.250000</td>\n      <td>14.250000</td>\n      <td>14.250000</td>\n      <td>1.000000</td>\n      <td>49.250000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 73
    }
   ],
   "source": [
    "headers = ['I1','I2','I3','I4','I5']\n",
    "df = pd.DataFrame(combinedinputs)\n",
    "df.columns = headers\n",
    "df['Transaction'] = t_or_n\n",
    "df['Outputs'] = combinedoutputs\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "unscaled_inputs = df.iloc[ :, 0 : 5 ]\n",
    "targets_all = df.iloc[ :, -2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_one_targets = int(np.sum(targets_all))\n",
    "zero_counter = 0\n",
    "indices_to_remove = []\n",
    "for i in range(targets_all.shape[0]):\n",
    "    if targets_all[i] == 0:\n",
    "        zero_counter += 1\n",
    "        if zero_counter > num_one_targets:\n",
    "            indices_to_remove.append(i)\n",
    "unscaled_inputs_equal_priors = np.delete(unscaled_inputs.values.tolist(), indices_to_remove, axis = 0)            \n",
    "targets_equal_priors = np.delete(targets_all.values.tolist(), indices_to_remove, axis = 0)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "scaled_inputs = preprocessing.scale(unscaled_inputs_equal_priors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_indices  = np.arange(scaled_inputs.shape[0])\n",
    "np.random.shuffle(shuffled_indices)\n",
    "\n",
    "shuffled_inputs = scaled_inputs[shuffled_indices]\n",
    "shuffled_targets = targets_equal_priors[shuffled_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(shuffled_inputs, shuffled_targets, random_state=0, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "40.8656334834051"
     },
     "metadata": {},
     "execution_count": 118
    }
   ],
   "source": [
    "import math\n",
    "math.sqrt(len(shuffled_targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='euclidean',\n                     metric_params=None, n_jobs=None, n_neighbors=39, p=2,\n                     weights='uniform')"
     },
     "metadata": {},
     "execution_count": 119
    }
   ],
   "source": [
    "classifier = KNeighborsClassifier(n_neighbors=39, p=2, metric = 'euclidean')\n",
    "classifier.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1,\n       0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0,\n       1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0,\n       1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0,\n       0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0,\n       1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1,\n       0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1,\n       1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n       0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1,\n       0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n       0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0,\n       1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n       1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1,\n       0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0,\n       0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n       0, 1, 1, 0])"
     },
     "metadata": {},
     "execution_count": 120
    }
   ],
   "source": [
    "y_pred = classifier.predict(x_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[[158  17]\n [ 16 143]]\n"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test,y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.896551724137931"
     },
     "metadata": {},
     "execution_count": 122
    }
   ],
   "source": [
    "f1_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0.9011976047904192\n"
    }
   ],
   "source": [
    "print(accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37764bitpy3tf20conda64b8e859d92746dc9b45e746292447ed",
   "display_name": "Python 3.7.7 64-bit ('py3-TF2.0': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}