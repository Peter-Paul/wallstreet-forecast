{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas_datareader as pdr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "              High          Low         Open        Close        Volume  \\\ncount  5056.000000  5056.000000  5056.000000  5056.000000  5.056000e+03   \nmean     15.134165    14.924315    15.035751    15.030289  1.669874e+05   \nstd       8.550389     8.352095     8.458185     8.450795  2.351958e+06   \nmin       4.026000     4.026000     4.026000     4.026000  0.000000e+00   \n25%       7.186500     7.140000     7.169750     7.170500  3.000000e+00   \n50%      15.256000    15.077500    15.182500    15.185500  3.100000e+01   \n75%      18.132250    18.001000    18.087750    18.068001  1.350000e+02   \nmax      49.520000    47.540001    48.459999    48.584000  6.980156e+07   \n\n         Adj Close  \ncount  5056.000000  \nmean     15.030289  \nstd       8.450795  \nmin       4.026000  \n25%       7.170500  \n50%      15.185500  \n75%      18.068001  \nmax      48.584000  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>High</th>\n      <th>Low</th>\n      <th>Open</th>\n      <th>Close</th>\n      <th>Volume</th>\n      <th>Adj Close</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>5056.000000</td>\n      <td>5056.000000</td>\n      <td>5056.000000</td>\n      <td>5056.000000</td>\n      <td>5.056000e+03</td>\n      <td>5056.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>15.134165</td>\n      <td>14.924315</td>\n      <td>15.035751</td>\n      <td>15.030289</td>\n      <td>1.669874e+05</td>\n      <td>15.030289</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>8.550389</td>\n      <td>8.352095</td>\n      <td>8.458185</td>\n      <td>8.450795</td>\n      <td>2.351958e+06</td>\n      <td>8.450795</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>4.026000</td>\n      <td>4.026000</td>\n      <td>4.026000</td>\n      <td>4.026000</td>\n      <td>0.000000e+00</td>\n      <td>4.026000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>7.186500</td>\n      <td>7.140000</td>\n      <td>7.169750</td>\n      <td>7.170500</td>\n      <td>3.000000e+00</td>\n      <td>7.170500</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>15.256000</td>\n      <td>15.077500</td>\n      <td>15.182500</td>\n      <td>15.185500</td>\n      <td>3.100000e+01</td>\n      <td>15.185500</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>18.132250</td>\n      <td>18.001000</td>\n      <td>18.087750</td>\n      <td>18.068001</td>\n      <td>1.350000e+02</td>\n      <td>18.068001</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>49.520000</td>\n      <td>47.540001</td>\n      <td>48.459999</td>\n      <td>48.584000</td>\n      <td>6.980156e+07</td>\n      <td>48.584000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "rawData = pdr.DataReader(\"SI=F\", \n",
    "                       start='2000-1-1', \n",
    "                       end='2020-5-10', \n",
    "                       data_source='yahoo')\n",
    "\n",
    "rawData.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "             High    Low   Open  Close   Volume  Adj Close    O-C  Trend  \\\nDate                                                                       \n2000-02-28  5.095  5.020  5.045  5.048  14203.0      5.048 -0.003      0   \n2000-02-29  5.090  5.035  5.065  5.048   2830.0      5.048  0.017      1   \n2000-03-01  5.130  5.050  5.070  5.073    511.0      5.073 -0.003      0   \n2000-03-02  5.105  5.000  5.105  5.008    645.0      5.008  0.097      1   \n2000-03-03  5.110  5.000  5.020  5.099    307.0      5.099 -0.079      0   \n\n            0.5(O+C)  0.5(H+L)  AvOC-HL  \nDate                                     \n2000-02-28    5.0465    5.0575  5.05200  \n2000-02-29    5.0565    5.0625  5.05950  \n2000-03-01    5.0715    5.0900  5.08075  \n2000-03-02    5.0565    5.0525  5.05450  \n2000-03-03    5.0595    5.0550  5.05725  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>High</th>\n      <th>Low</th>\n      <th>Open</th>\n      <th>Close</th>\n      <th>Volume</th>\n      <th>Adj Close</th>\n      <th>O-C</th>\n      <th>Trend</th>\n      <th>0.5(O+C)</th>\n      <th>0.5(H+L)</th>\n      <th>AvOC-HL</th>\n    </tr>\n    <tr>\n      <th>Date</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2000-02-28</th>\n      <td>5.095</td>\n      <td>5.020</td>\n      <td>5.045</td>\n      <td>5.048</td>\n      <td>14203.0</td>\n      <td>5.048</td>\n      <td>-0.003</td>\n      <td>0</td>\n      <td>5.0465</td>\n      <td>5.0575</td>\n      <td>5.05200</td>\n    </tr>\n    <tr>\n      <th>2000-02-29</th>\n      <td>5.090</td>\n      <td>5.035</td>\n      <td>5.065</td>\n      <td>5.048</td>\n      <td>2830.0</td>\n      <td>5.048</td>\n      <td>0.017</td>\n      <td>1</td>\n      <td>5.0565</td>\n      <td>5.0625</td>\n      <td>5.05950</td>\n    </tr>\n    <tr>\n      <th>2000-03-01</th>\n      <td>5.130</td>\n      <td>5.050</td>\n      <td>5.070</td>\n      <td>5.073</td>\n      <td>511.0</td>\n      <td>5.073</td>\n      <td>-0.003</td>\n      <td>0</td>\n      <td>5.0715</td>\n      <td>5.0900</td>\n      <td>5.08075</td>\n    </tr>\n    <tr>\n      <th>2000-03-02</th>\n      <td>5.105</td>\n      <td>5.000</td>\n      <td>5.105</td>\n      <td>5.008</td>\n      <td>645.0</td>\n      <td>5.008</td>\n      <td>0.097</td>\n      <td>1</td>\n      <td>5.0565</td>\n      <td>5.0525</td>\n      <td>5.05450</td>\n    </tr>\n    <tr>\n      <th>2000-03-03</th>\n      <td>5.110</td>\n      <td>5.000</td>\n      <td>5.020</td>\n      <td>5.099</td>\n      <td>307.0</td>\n      <td>5.099</td>\n      <td>-0.079</td>\n      <td>0</td>\n      <td>5.0595</td>\n      <td>5.0550</td>\n      <td>5.05725</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "rawData['O-C'] = rawData['Open'] - rawData['Close']\n",
    "\n",
    "trend = []\n",
    "for i in range(len(rawData)):\n",
    "    if rawData['O-C'][i] >= 0:\n",
    "        trend.append(1)\n",
    "    else:\n",
    "        trend.append(0)\n",
    "rawData['Trend'] = trend\n",
    "\n",
    "rawData['0.5(O+C)'] = ( rawData['Open'] + rawData['Close'] ) * 0.5\n",
    "rawData['0.5(H+L)'] = ( rawData['High'] + rawData['Low'] ) * 0.5\n",
    "rawData['AvOC-HL'] = (rawData['0.5(O+C)'] + rawData['0.5(H+L)']) * 0.5\n",
    "rawData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "av5 = []\n",
    "p = 0\n",
    "h = 0\n",
    "for i in range(len(rawData)):\n",
    "    p += 1\n",
    "    for x in range(5):\n",
    "        h = x+p\n",
    "    av5.append(rawData[['Volume']][i:h].mean().to_numpy())\n",
    "\n",
    "edited_av5 = av5[ 0 : len(rawData) - 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[-0.08728493],\n       [-0.08891077],\n       [-0.0892072 ],\n       ...,\n       [ 1.60323467],\n       [ 3.98858298],\n       [ 6.23862759]])"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "inputs = rawData[['High', 'Low', 'Open', 'Close']][ 0 : len(rawData) - 1 ].to_numpy()\n",
    "inputs2 = rawData[['High', 'Low','Volume']][ 0 : len(rawData) - 1 ].to_numpy()\n",
    "inputs3 = rawData['Volume'][ 0 : len(rawData) - 1 ].to_numpy()\n",
    "inputs4  = edited_av5\n",
    "\n",
    "targets = rawData[['Trend']][ 6 : len(rawData) ].to_numpy()\n",
    "\n",
    "scaler = StandardScaler()\n",
    "# scaler.fit(inputs)\n",
    "# scaler.fit(inputs2)\n",
    "# scaler.fit(inputs3.reshape(-1,1))\n",
    "scaler.fit(inputs4)\n",
    "\n",
    "# scaled_inputs = scaler.transform(inputs)\n",
    "# scaled_inputs2 = scaler.transform(inputs2)\n",
    "# scaled_inputs3 = scaler.transform(inputs3.reshape(-1,1))\n",
    "scaled_inputs4 = scaler.transform(inputs4)\n",
    "\n",
    "\n",
    "scaled_inputs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "5050 5050 []\n"
    }
   ],
   "source": [
    "sum_uptrend = int(np.sum(targets))\n",
    "\n",
    "sum_downtrend = 0\n",
    "\n",
    "unnecessary_indices = []\n",
    "\n",
    "for i in range(len(targets)):\n",
    "    if targets[i] == 0:\n",
    "        sum_downtrend += 1\n",
    "        if sum_downtrend > sum_uptrend:\n",
    "            unnecessary_indices.append(i)\n",
    "\n",
    "extracted_inputs = np.delete( scaled_inputs4, unnecessary_indices, axis = 0 )\n",
    "extracted_targets = np.delete( targets, unnecessary_indices, axis = 0 )\n",
    "print(len(extracted_inputs), len(extracted_targets), unnecessary_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[-0.08937807],\n       [-0.08939669],\n       [-0.08941461],\n       ...,\n       [-0.08617506],\n       [-0.08930847],\n       [11.81152312]])"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "shuffle_value = np.arange(len(extracted_inputs))\n",
    "np.random.shuffle(shuffle_value)\n",
    "\n",
    "shuffled_inputs = extracted_inputs[shuffle_value]\n",
    "shuffled_targets = extracted_targets[shuffle_value]\n",
    "shuffled_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "2705 4040 0.6695544554455446\n346 505 0.6851485148514852\n339 505 0.6712871287128713\n"
    }
   ],
   "source": [
    "total_samples = len(shuffled_inputs)\n",
    "\n",
    "train_samples = int( 0.8 * total_samples )\n",
    "validation_samples = int( 0.1 * total_samples )\n",
    "test_samples = total_samples - ( train_samples + validation_samples )\n",
    "\n",
    "train_inputs = shuffled_inputs[ :  train_samples]\n",
    "train_targets = shuffled_targets[ : train_samples]\n",
    "\n",
    "validation_inputs = shuffled_inputs[ train_samples : train_samples + validation_samples ]\n",
    "validation_targets = shuffled_targets[ train_samples : train_samples + validation_samples ]\n",
    "\n",
    "test_inputs = shuffled_inputs[ train_samples + validation_samples : ]\n",
    "test_targets = shuffled_targets[ train_samples + validation_samples : ]\n",
    "\n",
    "print( np.sum(train_targets), train_samples, np.sum(train_targets) /  train_samples )\n",
    "print( np.sum(validation_targets), validation_samples, np.sum(validation_targets) /  validation_samples )\n",
    "print( np.sum(test_targets), test_samples, np.sum(test_targets) /  test_samples )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('silver_train', inputs=train_inputs, targets=train_targets)\n",
    "np.savez('silver_validation', inputs=validation_inputs, targets=validation_targets)\n",
    "np.savez('silver_test', inputs=test_inputs, targets=test_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "npz_trn = np.load('silver_train.npz')\n",
    "trn_inputs, trn_targets = npz_trn['inputs'].astype(np.float), npz_trn['targets'].astype(np.int)\n",
    "\n",
    "npz_val = np.load('silver_validation.npz')\n",
    "val_inputs, val_targets = npz_val['inputs'].astype(np.float), npz_val['targets'].astype(np.int)\n",
    "\n",
    "npz_tst = np.load('silver_test.npz')\n",
    "tst_inputs, tst_targets = npz_tst['inputs'].astype(np.float), npz_tst['targets'].astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[-0.08937807],\n       [-0.08939669],\n       [-0.08941461],\n       ...,\n       [-0.08942154],\n       [-0.08929136],\n       [-0.0894175 ]])"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "train_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Train on 4040 samples, validate on 505 samples\nEpoch 1/50\n4040/4040 - 1s - loss: 0.6501 - accuracy: 0.6696 - val_loss: 0.6258 - val_accuracy: 0.6851\nEpoch 2/50\n4040/4040 - 0s - loss: 0.6350 - accuracy: 0.6696 - val_loss: 0.6243 - val_accuracy: 0.6851\nEpoch 3/50\n4040/4040 - 0s - loss: 0.6347 - accuracy: 0.6696 - val_loss: 0.6227 - val_accuracy: 0.6851\nEpoch 4/50\n4040/4040 - 0s - loss: 0.6348 - accuracy: 0.6696 - val_loss: 0.6288 - val_accuracy: 0.6851\nEpoch 5/50\n4040/4040 - 0s - loss: 0.6354 - accuracy: 0.6696 - val_loss: 0.6228 - val_accuracy: 0.6851\nEpoch 6/50\n4040/4040 - 0s - loss: 0.6346 - accuracy: 0.6696 - val_loss: 0.6232 - val_accuracy: 0.6851\nEpoch 7/50\n4040/4040 - 0s - loss: 0.6356 - accuracy: 0.6696 - val_loss: 0.6240 - val_accuracy: 0.6851\nEpoch 8/50\n4040/4040 - 0s - loss: 0.6346 - accuracy: 0.6696 - val_loss: 0.6229 - val_accuracy: 0.6851\nEpoch 9/50\n4040/4040 - 0s - loss: 0.6356 - accuracy: 0.6696 - val_loss: 0.6278 - val_accuracy: 0.6851\nEpoch 10/50\n4040/4040 - 0s - loss: 0.6346 - accuracy: 0.6696 - val_loss: 0.6229 - val_accuracy: 0.6851\nEpoch 11/50\n4040/4040 - 0s - loss: 0.6351 - accuracy: 0.6696 - val_loss: 0.6238 - val_accuracy: 0.6851\nEpoch 12/50\n4040/4040 - 0s - loss: 0.6349 - accuracy: 0.6696 - val_loss: 0.6244 - val_accuracy: 0.6851\nEpoch 13/50\n4040/4040 - 0s - loss: 0.6344 - accuracy: 0.6696 - val_loss: 0.6230 - val_accuracy: 0.6851\nEpoch 14/50\n4040/4040 - 0s - loss: 0.6351 - accuracy: 0.6696 - val_loss: 0.6232 - val_accuracy: 0.6851\nEpoch 15/50\n4040/4040 - 0s - loss: 0.6348 - accuracy: 0.6696 - val_loss: 0.6239 - val_accuracy: 0.6851\nEpoch 16/50\n4040/4040 - 0s - loss: 0.6345 - accuracy: 0.6696 - val_loss: 0.6241 - val_accuracy: 0.6851\nEpoch 17/50\n4040/4040 - 0s - loss: 0.6344 - accuracy: 0.6696 - val_loss: 0.6226 - val_accuracy: 0.6851\nEpoch 18/50\n4040/4040 - 0s - loss: 0.6357 - accuracy: 0.6696 - val_loss: 0.6228 - val_accuracy: 0.6851\nEpoch 19/50\n4040/4040 - 0s - loss: 0.6349 - accuracy: 0.6696 - val_loss: 0.6255 - val_accuracy: 0.6851\nEpoch 20/50\n4040/4040 - 0s - loss: 0.6345 - accuracy: 0.6696 - val_loss: 0.6233 - val_accuracy: 0.6851\nEpoch 21/50\n4040/4040 - 0s - loss: 0.6343 - accuracy: 0.6696 - val_loss: 0.6225 - val_accuracy: 0.6851\nEpoch 22/50\n4040/4040 - 0s - loss: 0.6354 - accuracy: 0.6696 - val_loss: 0.6245 - val_accuracy: 0.6851\nEpoch 23/50\n4040/4040 - 0s - loss: 0.6344 - accuracy: 0.6696 - val_loss: 0.6239 - val_accuracy: 0.6851\nEpoch 24/50\n4040/4040 - 0s - loss: 0.6350 - accuracy: 0.6696 - val_loss: 0.6238 - val_accuracy: 0.6851\nEpoch 25/50\n4040/4040 - 0s - loss: 0.6355 - accuracy: 0.6696 - val_loss: 0.6228 - val_accuracy: 0.6851\nEpoch 26/50\n4040/4040 - 0s - loss: 0.6346 - accuracy: 0.6696 - val_loss: 0.6228 - val_accuracy: 0.6851\nEpoch 27/50\n4040/4040 - 0s - loss: 0.6349 - accuracy: 0.6696 - val_loss: 0.6228 - val_accuracy: 0.6851\nEpoch 28/50\n4040/4040 - 0s - loss: 0.6349 - accuracy: 0.6696 - val_loss: 0.6227 - val_accuracy: 0.6851\nEpoch 29/50\n4040/4040 - 0s - loss: 0.6348 - accuracy: 0.6696 - val_loss: 0.6231 - val_accuracy: 0.6851\nEpoch 30/50\n4040/4040 - 0s - loss: 0.6349 - accuracy: 0.6696 - val_loss: 0.6232 - val_accuracy: 0.6851\nEpoch 31/50\n4040/4040 - 0s - loss: 0.6347 - accuracy: 0.6696 - val_loss: 0.6232 - val_accuracy: 0.6851\nEpoch 32/50\n4040/4040 - 0s - loss: 0.6350 - accuracy: 0.6696 - val_loss: 0.6239 - val_accuracy: 0.6851\nEpoch 33/50\n4040/4040 - 0s - loss: 0.6346 - accuracy: 0.6696 - val_loss: 0.6232 - val_accuracy: 0.6851\nEpoch 34/50\n4040/4040 - 0s - loss: 0.6349 - accuracy: 0.6696 - val_loss: 0.6241 - val_accuracy: 0.6851\nEpoch 35/50\n4040/4040 - 0s - loss: 0.6348 - accuracy: 0.6696 - val_loss: 0.6230 - val_accuracy: 0.6851\nEpoch 36/50\n4040/4040 - 0s - loss: 0.6348 - accuracy: 0.6696 - val_loss: 0.6240 - val_accuracy: 0.6851\nEpoch 37/50\n4040/4040 - 0s - loss: 0.6355 - accuracy: 0.6696 - val_loss: 0.6227 - val_accuracy: 0.6851\nEpoch 38/50\n4040/4040 - 0s - loss: 0.6356 - accuracy: 0.6696 - val_loss: 0.6231 - val_accuracy: 0.6851\nEpoch 39/50\n4040/4040 - 0s - loss: 0.6347 - accuracy: 0.6696 - val_loss: 0.6238 - val_accuracy: 0.6851\nEpoch 40/50\n4040/4040 - 0s - loss: 0.6347 - accuracy: 0.6696 - val_loss: 0.6224 - val_accuracy: 0.6851\nEpoch 41/50\n4040/4040 - 0s - loss: 0.6351 - accuracy: 0.6696 - val_loss: 0.6231 - val_accuracy: 0.6851\nEpoch 42/50\n4040/4040 - 0s - loss: 0.6353 - accuracy: 0.6696 - val_loss: 0.6236 - val_accuracy: 0.6851\nEpoch 43/50\n4040/4040 - 0s - loss: 0.6345 - accuracy: 0.6696 - val_loss: 0.6263 - val_accuracy: 0.6851\nEpoch 44/50\n4040/4040 - 0s - loss: 0.6352 - accuracy: 0.6696 - val_loss: 0.6241 - val_accuracy: 0.6851\nEpoch 45/50\n4040/4040 - 0s - loss: 0.6347 - accuracy: 0.6696 - val_loss: 0.6244 - val_accuracy: 0.6851\nEpoch 46/50\n4040/4040 - 0s - loss: 0.6347 - accuracy: 0.6696 - val_loss: 0.6239 - val_accuracy: 0.6851\nEpoch 47/50\n4040/4040 - 0s - loss: 0.6345 - accuracy: 0.6696 - val_loss: 0.6234 - val_accuracy: 0.6851\nEpoch 48/50\n4040/4040 - 0s - loss: 0.6350 - accuracy: 0.6696 - val_loss: 0.6229 - val_accuracy: 0.6851\nEpoch 49/50\n4040/4040 - 0s - loss: 0.6346 - accuracy: 0.6696 - val_loss: 0.6239 - val_accuracy: 0.6851\nEpoch 50/50\n4040/4040 - 0s - loss: 0.6344 - accuracy: 0.6696 - val_loss: 0.6232 - val_accuracy: 0.6851\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x23635155d48>"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "input_size = 1\n",
    "output_size = 2\n",
    "\n",
    "hidden_layer_size = 100\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(hidden_layer_size, activation='relu'), \n",
    "    tf.keras.layers.Dense(hidden_layer_size, activation='relu'), \n",
    "    tf.keras.layers.Dense(hidden_layer_size, activation='relu'), \n",
    "    tf.keras.layers.Dense(output_size, activation='softmax') \n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "batch_size = 100\n",
    "\n",
    "epochs = 50\n",
    "\n",
    "model.fit(trn_inputs,\n",
    "          trn_targets,\n",
    "          batch_size=batch_size, \n",
    "          epochs=epochs,\n",
    "          validation_data=(val_inputs, val_targets),\n",
    "          verbose = 2 \n",
    "          )  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "505/505 [==============================] - 0s 75us/sample - loss: 0.6335 - accuracy: 0.6713\n"
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(tst_inputs, tst_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37764bitpy3tf20conda64b8e859d92746dc9b45e746292447ed",
   "display_name": "Python 3.7.7 64-bit ('py3-TF2.0': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}